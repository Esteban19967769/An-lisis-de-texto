library(readtext)
library(syuzhet)
library(tidytext)
library(stringr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
mensajes <- readtext("/Users/Luis/Downloads/eval-texto_Lopez_Esteban/datos/programas_2021/",
docvarsfrom = "filenames",
docvarnames = c("fecha", "presidente", "coalicion","primera-vuelta"), #me crea variables a partir de la info del documentos
dvsep = "_",
encoding = "UTF-8")
head(mensajes)
unas_stopwords <- read_csv("https://raw.githubusercontent.com/7PartidasDigital/AnaText/master/datos/diccionarios/vacias.txt")
mensajes %>%
unnest_tokens(input = text, output = palabra, strip_numeric = TRUE,  collapse = "presidente") %>% #mantenemos la fecha con cada palabra asociada
count(presidente, palabra, sort = TRUE) %>% #si ejecuto este codico hasta aca, me aparecen string con numeros raros y los quiero eliminar, aplico un filter
filter(!str_detect(palabra, "^\\d"))  #eliminar str que elimine palabras que comiencen con numero
mensajes <- readtext("/Users/Luis/Downloads/eval-texto_Lopez_Esteban/datos/programas_2021/",
docvarsfrom = "filenames",
docvarnames = c("fecha", "candidato", "coalicion","primera-vuelta"), #me crea variables a partir de la info del documentos
dvsep = "_",
encoding = "UTF-8")
head(mensajes)
mensajes %>%
unnest_tokens(input = text, output = palabra, strip_numeric = TRUE,  collapse = "presidente") %>% #mantenemos al candidato con cada palabra asociada
count(presidente, palabra, sort = TRUE) %>% #si ejecuto este codico hasta aca, me aparecen string con numeros raros y los quiero eliminar, aplico un filter
filter(!str_detect(palabra, "^\\d"))  #eliminar str que elimine palabras que comiencen con numero
mensajes %>%
unnest_tokens(input = text, output = palabra, strip_numeric = TRUE,  collapse = "presidente") %>% #mantenemos al candidato con cada palabra asociada
count(candidato, palabra, sort = TRUE) %>% #si ejecuto este codico hasta aca, me aparecen string con numeros raros y los quiero eliminar, aplico un filter
filter(!str_detect(palabra, "^\\d"))  #eliminar str que elimine palabras que comiencen con numero
mensajes %>%
unnest_tokens(input = text, output = palabra, strip_numeric = TRUE,  collapse = "candidato") %>% #mantenemos al candidato con cada palabra asociada
count(candidato, palabra, sort = TRUE) %>% #si ejecuto este codico hasta aca, me aparecen string con numeros raros y los quiero eliminar, aplico un filter
filter(!str_detect(palabra, "^\\d"))  #eliminar str que elimine palabras que comiencen con numero
frecuencias_mensajes <- mensajes %>%
unnest_tokens(input = text, output = palabra, strip_numeric = TRUE,  collapse = "candidato") %>% #mantenemos al candidato con cada palabra asociada
count(candidato, palabra, sort = TRUE) %>% #si ejecuto este codico hasta aca, me aparecen string con numeros raros y los quiero eliminar, aplico un filter
filter(!str_detect(palabra, "^\\d"))  %>% #eliminar str que elimine palabras que comiencen con numero
anti_join(unas_stopwords)
frecuencias_mensajes
tf_idf_mensajes <- bind_tf_idf(frecuencias_mensajes,
term = palabra,
document = candidato,
n = n)
tf_idf_mensajes
#ordenamos idf
tf_idf_mensajes %>%
arrange(desc(tf_idf))
#
tf_idf_mensajes %>%
arrange(desc(tf_idf)) %>%
group_by(fecha) %>%
slice_max(tf_idf, n = 10)
#
tf_idf_mensajes %>%
arrange(desc(tf_idf)) %>%
group_by(candidato) %>%
slice_max(tf_idf, n = 10)
#
tf_idf_mensajes %>%
arrange(desc(tf_idf)) %>%
group_by(candidato) %>%
slice_max(tf_idf, n = 10) %>%
ggplot(aes(y = reorder(palabra, tf_idf), x = tf_idf, fill = candidato)) +
geom_col(show.legend = FALSE) +
facet_wrap(~candidato, scales = "free")
otras_stopwords <- tibble(palabra = c("ciÃ³n","nes","com","https"))
frecuencias_mensajes <- mensajes %>%
unnest_tokens(input = text, output = palabra, strip_numeric = TRUE,  collapse = "candidato") %>% #mantenemos al candidato con cada palabra asociada
count(candidato, palabra, sort = TRUE) %>% #si ejecuto este codico hasta aca, me aparecen string con numeros raros y los quiero eliminar, aplico un filter
filter(!str_detect(palabra, "^\\d"))  %>% #eliminar str que elimine palabras que comiencen con numero
anti_join(unas_stopwords) +
anti_join(otras_stopwords)
frecuencias_mensajes
tf_idf_mensajes <- bind_tf_idf(frecuencias_mensajes,
term = palabra,
document = candidato,
n = n)
tf_idf_mensajes
#ordenamos idf
tf_idf_mensajes %>%
arrange(desc(tf_idf))
#con un n de 10
tf_idf_mensajes %>%
arrange(desc(tf_idf)) %>%
group_by(candidato) %>%
slice_max(tf_idf, n = 10)
#
tf_idf_mensajes %>%
arrange(desc(tf_idf)) %>%
group_by(candidato) %>%
slice_max(tf_idf, n = 10) %>%
ggplot(aes(y = reorder(palabra, tf_idf), x = tf_idf, fill = candidato)) +
geom_col(show.legend = FALSE) +
facet_wrap(~candidato, scales = "free")
frecuencias_mensajes <- mensajes %>%
unnest_tokens(input = text, output = palabra, strip_numeric = TRUE,  collapse = "candidato") %>% #mantenemos al candidato con cada palabra asociada
count(candidato, palabra, sort = TRUE) %>% #si ejecuto este codico hasta aca, me aparecen string con numeros raros y los quiero eliminar, aplico un filter
filter(!str_detect(palabra, "^\\d"))  %>% #eliminar str que elimine palabras que comiencen con numero
anti_join(unas_stopwords) +
anti_join(otras_stopwords)
frecuencias_mensajes <- mensajes %>%
unnest_tokens(input = text, output = palabra, strip_numeric = TRUE,  collapse = "candidato") %>% #mantenemos al candidato con cada palabra asociada
count(candidato, palabra, sort = TRUE) %>% #si ejecuto este codico hasta aca, me aparecen string con numeros raros y los quiero eliminar, aplico un filter
filter(!str_detect(palabra, "^\\d"))  %>% #eliminar str que elimine palabras que comiencen con numero
anti_join(unas_stopwords) %>%
anti_join(otras_stopwords)
frecuencias_mensajes
tf_idf_mensajes <- bind_tf_idf(frecuencias_mensajes,
term = palabra,
document = candidato,
n = n)
tf_idf_mensajes
#ordenamos idf
tf_idf_mensajes %>%
arrange(desc(tf_idf))
#con un n de 10
tf_idf_mensajes %>%
arrange(desc(tf_idf)) %>%
group_by(candidato) %>%
slice_max(tf_idf, n = 10)
#
tf_idf_mensajes %>%
arrange(desc(tf_idf)) %>%
group_by(candidato) %>%
slice_max(tf_idf, n = 10) %>%
ggplot(aes(y = reorder(palabra, tf_idf), x = tf_idf, fill = candidato)) +
geom_col(show.legend = FALSE) +
facet_wrap(~candidato, scales = "free")
ggsave("/Users/Luis/Downloads/eval-texto_Lopez_Esteban/figuras/idf_mensajes.png", height = 7, width = 10)
#Cargar paquetes
#Traer codigo html y buscar etiquetas que nos interesan
install.packages("rvest")
library(rvest)
install.packages("robotstxt")
library(robotstxt)
library(dplyr) #para filtro,pipe,etc
install.packages("stringr")
library(stringr)
library(tidyr)
library(lubridate)
library(purrr)
install.packages("beepr")
library(beepr) #me sirve para reproducir sonido y nos avise
#que el proceso termine de ejecutarse
html_noticia_ejemplo <- read_html("https://www.elmostrador.cl/claves/cambio-climatico")
titular <- html_noticia_ejemplo %>%
html_element("h1") %>%
html_text()
bajada <- html_noticia_ejemplo %>%
html_element(".excerpt") %>%
html_text()
cuerpo <- html_noticia_ejemplo %>%
html_elements(".paragraph") %>%
html_text()
paste0(c(titular, bajada, cuerpo), collapse = "\n") %>%
writeLines("datos/noticia-ejemplo.txt")
extraer_noticia <- function(enlace){
#Sys.sleep(2) #cuando ejecuta la funcion, contara 2 sgdos
#extraer el codigo html
html_noticia <- read_html(enlace)
titular <- html_noticia %>%
html_element("h1") %>%
html_text()
bajada <- html_noticia %>%
html_element(".excerpt") %>%
html_text()
cuerpo <- html_noticia %>%
html_elements(".paragraph") %>%
html_text()
paste0(c(titular, bajada, cuerpo), collapse = "\n")
}
extraer_titulares_cc <- function(numero_pagina){
Sys.sleep(2)
# crear el enlace
enlace <- paste0("https://www.elmostrador.cl/claves/cambio-climatico", numero_pagina)
# extraemos el html
html <- read_html(enlace)
titulares <- html %>%
html_elements("h3 a") %>%
html_text(trim = TRUE)
enlaces <- html %>%
html_elements("h3 a") %>%
html_attr("href") %>%
paste0("https://www.elmostrador.cl", .)
tibble(titular = titulares, enlace_noticia = enlaces) %>%
separate(titular, into = c("seccion", "titular"), sep = "  ", extra = "merge")
}
extraer_titulares_cc(5)
map(1:3, extraer_titulares_cc)
total_paginas <- read_html("https://www.elmostrador.cl/claves/cambio-climatico") %>%
html_element(".pagination-info") %>%
html_text() %>%
str_extract("[:digit:]+$") %>%  # \\d
as.numeric()
titulares_cambio_climatico <- map_df(1:total_paginas, extraer_titulares_cc)
